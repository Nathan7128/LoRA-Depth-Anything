{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cfd38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoImageProcessor, \n",
    "    AutoModelForDepthEstimation, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a692bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, pairs_list, images_path, depth_npy_path, image_processor):\n",
    "        self.pairs_list = pairs_list  # Liste des paires (image_filename, depth_filename)\n",
    "        self.images_path = images_path\n",
    "        self.depth_npy_path = depth_npy_path\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name, depth_npy_name = self.pairs_list[idx]\n",
    "        \n",
    "        # Chargement à la demande\n",
    "        image_file = os.path.join(self.images_path, image_name)\n",
    "        depth_npy_file = os.path.join(self.depth_npy_path, depth_npy_name)\n",
    "        \n",
    "        image = Image.open(image_file).convert(\"RGB\")\n",
    "        depth_npy = np.load(depth_npy_file)\n",
    "        \n",
    "        # CORRECTION ICI : Gestion des canaux de profondeur\n",
    "        # Si la depth a 3 canaux (H, W, 3), on ne garde que le premier (H, W)\n",
    "        if len(depth_npy.shape) == 3:\n",
    "            depth_npy = depth_npy[:, :, 0]\n",
    "        \n",
    "        # Prétraitement de l'image\n",
    "        inputs = self.image_processor(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        # Conversion en Tensor\n",
    "        depth_tensor = torch.from_numpy(depth_npy).float()\n",
    "        \n",
    "        # On a maintenant une forme (H, W). \n",
    "        # On ajoute (Batch, Channel) pour obtenir (1, 1, H, W) requis par interpolate\n",
    "        depth_tensor = depth_tensor.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # Récupération de la taille cible\n",
    "        target_size = inputs['pixel_values'].shape[-2:]\n",
    "        \n",
    "        # Interpolation\n",
    "        depth_resized = F.interpolate(depth_tensor, size=target_size, mode='nearest')\n",
    "        \n",
    "        # On retire les dimensions pour revenir à (H, W) pour les labels\n",
    "        depth_resized = depth_resized.squeeze()\n",
    "\n",
    "        return {\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(0),\n",
    "            'labels': depth_resized,\n",
    "            'image': image  # Ajouter l'image originale pour visualisation\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "557b9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chargement du Modèle et Processor\n",
    "model_id = \"depth-anything/Depth-Anything-V2-Small-hf\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForDepthEstimation.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b162b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Préparation des données (comme dans ton code original)\n",
    "# Assure-toi que 'dataset' (ta classe DatasetImages) est bien instancié avant\n",
    "dataset_path = \"DATASET_DEVOIR\"\n",
    "images_path = os.path.join(dataset_path, \"images\")\n",
    "depth_npy_path = os.path.join(dataset_path, \"depth\")\n",
    "image_files = sorted(os.listdir(images_path))\n",
    "depth_files = sorted(os.listdir(depth_npy_path))\n",
    "# Filtrer pour s'assurer que les fichiers correspondent bien si nécessaire\n",
    "all_pairs = list(zip(image_files, depth_files))\n",
    "random.shuffle(all_pairs)\n",
    "\n",
    "total = len(all_pairs)\n",
    "train_split = int(0.7 * total)\n",
    "eval_split = int(0.85 * total)\n",
    "\n",
    "train_pairs = all_pairs[:train_split]\n",
    "eval_pairs = all_pairs[train_split:eval_split]\n",
    "test_pairs = all_pairs[eval_split:]\n",
    "\n",
    "train_dataset = DepthDataset(train_pairs, images_path, depth_npy_path, image_processor)\n",
    "eval_dataset = DepthDataset(eval_pairs, images_path, depth_npy_path, image_processor)\n",
    "test_dataset = DepthDataset(test_pairs, images_path, depth_npy_path, image_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "625ede33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms de toutes les couches du modèle :\n",
      "backbone\n",
      "backbone.embeddings\n",
      "backbone.embeddings.patch_embeddings\n",
      "backbone.embeddings.patch_embeddings.projection\n",
      "backbone.embeddings.dropout\n",
      "backbone.encoder\n",
      "backbone.encoder.layer\n",
      "backbone.encoder.layer.0\n",
      "backbone.encoder.layer.0.norm1\n",
      "backbone.encoder.layer.0.attention\n",
      "backbone.encoder.layer.0.attention.attention\n",
      "backbone.encoder.layer.0.attention.attention.query\n",
      "backbone.encoder.layer.0.attention.attention.key\n",
      "backbone.encoder.layer.0.attention.attention.value\n",
      "backbone.encoder.layer.0.attention.output\n",
      "backbone.encoder.layer.0.attention.output.dense\n",
      "backbone.encoder.layer.0.attention.output.dropout\n",
      "backbone.encoder.layer.0.layer_scale1\n",
      "backbone.encoder.layer.0.drop_path\n",
      "backbone.encoder.layer.0.norm2\n",
      "backbone.encoder.layer.0.mlp\n",
      "backbone.encoder.layer.0.mlp.fc1\n",
      "backbone.encoder.layer.0.mlp.activation\n",
      "backbone.encoder.layer.0.mlp.fc2\n",
      "backbone.encoder.layer.0.layer_scale2\n",
      "backbone.encoder.layer.1\n",
      "backbone.encoder.layer.1.norm1\n",
      "backbone.encoder.layer.1.attention\n",
      "backbone.encoder.layer.1.attention.attention\n",
      "backbone.encoder.layer.1.attention.attention.query\n",
      "backbone.encoder.layer.1.attention.attention.key\n",
      "backbone.encoder.layer.1.attention.attention.value\n",
      "backbone.encoder.layer.1.attention.output\n",
      "backbone.encoder.layer.1.attention.output.dense\n",
      "backbone.encoder.layer.1.attention.output.dropout\n",
      "backbone.encoder.layer.1.layer_scale1\n",
      "backbone.encoder.layer.1.drop_path\n",
      "backbone.encoder.layer.1.norm2\n",
      "backbone.encoder.layer.1.mlp\n",
      "backbone.encoder.layer.1.mlp.fc1\n",
      "backbone.encoder.layer.1.mlp.activation\n",
      "backbone.encoder.layer.1.mlp.fc2\n",
      "backbone.encoder.layer.1.layer_scale2\n",
      "backbone.encoder.layer.2\n",
      "backbone.encoder.layer.2.norm1\n",
      "backbone.encoder.layer.2.attention\n",
      "backbone.encoder.layer.2.attention.attention\n",
      "backbone.encoder.layer.2.attention.attention.query\n",
      "backbone.encoder.layer.2.attention.attention.key\n",
      "backbone.encoder.layer.2.attention.attention.value\n",
      "backbone.encoder.layer.2.attention.output\n",
      "backbone.encoder.layer.2.attention.output.dense\n",
      "backbone.encoder.layer.2.attention.output.dropout\n",
      "backbone.encoder.layer.2.layer_scale1\n",
      "backbone.encoder.layer.2.drop_path\n",
      "backbone.encoder.layer.2.norm2\n",
      "backbone.encoder.layer.2.mlp\n",
      "backbone.encoder.layer.2.mlp.fc1\n",
      "backbone.encoder.layer.2.mlp.activation\n",
      "backbone.encoder.layer.2.mlp.fc2\n",
      "backbone.encoder.layer.2.layer_scale2\n",
      "backbone.encoder.layer.3\n",
      "backbone.encoder.layer.3.norm1\n",
      "backbone.encoder.layer.3.attention\n",
      "backbone.encoder.layer.3.attention.attention\n",
      "backbone.encoder.layer.3.attention.attention.query\n",
      "backbone.encoder.layer.3.attention.attention.key\n",
      "backbone.encoder.layer.3.attention.attention.value\n",
      "backbone.encoder.layer.3.attention.output\n",
      "backbone.encoder.layer.3.attention.output.dense\n",
      "backbone.encoder.layer.3.attention.output.dropout\n",
      "backbone.encoder.layer.3.layer_scale1\n",
      "backbone.encoder.layer.3.drop_path\n",
      "backbone.encoder.layer.3.norm2\n",
      "backbone.encoder.layer.3.mlp\n",
      "backbone.encoder.layer.3.mlp.fc1\n",
      "backbone.encoder.layer.3.mlp.activation\n",
      "backbone.encoder.layer.3.mlp.fc2\n",
      "backbone.encoder.layer.3.layer_scale2\n",
      "backbone.encoder.layer.4\n",
      "backbone.encoder.layer.4.norm1\n",
      "backbone.encoder.layer.4.attention\n",
      "backbone.encoder.layer.4.attention.attention\n",
      "backbone.encoder.layer.4.attention.attention.query\n",
      "backbone.encoder.layer.4.attention.attention.key\n",
      "backbone.encoder.layer.4.attention.attention.value\n",
      "backbone.encoder.layer.4.attention.output\n",
      "backbone.encoder.layer.4.attention.output.dense\n",
      "backbone.encoder.layer.4.attention.output.dropout\n",
      "backbone.encoder.layer.4.layer_scale1\n",
      "backbone.encoder.layer.4.drop_path\n",
      "backbone.encoder.layer.4.norm2\n",
      "backbone.encoder.layer.4.mlp\n",
      "backbone.encoder.layer.4.mlp.fc1\n",
      "backbone.encoder.layer.4.mlp.activation\n",
      "backbone.encoder.layer.4.mlp.fc2\n",
      "backbone.encoder.layer.4.layer_scale2\n",
      "backbone.encoder.layer.5\n",
      "backbone.encoder.layer.5.norm1\n",
      "backbone.encoder.layer.5.attention\n",
      "backbone.encoder.layer.5.attention.attention\n",
      "backbone.encoder.layer.5.attention.attention.query\n",
      "backbone.encoder.layer.5.attention.attention.key\n",
      "backbone.encoder.layer.5.attention.attention.value\n",
      "backbone.encoder.layer.5.attention.output\n",
      "backbone.encoder.layer.5.attention.output.dense\n",
      "backbone.encoder.layer.5.attention.output.dropout\n",
      "backbone.encoder.layer.5.layer_scale1\n",
      "backbone.encoder.layer.5.drop_path\n",
      "backbone.encoder.layer.5.norm2\n",
      "backbone.encoder.layer.5.mlp\n",
      "backbone.encoder.layer.5.mlp.fc1\n",
      "backbone.encoder.layer.5.mlp.activation\n",
      "backbone.encoder.layer.5.mlp.fc2\n",
      "backbone.encoder.layer.5.layer_scale2\n",
      "backbone.encoder.layer.6\n",
      "backbone.encoder.layer.6.norm1\n",
      "backbone.encoder.layer.6.attention\n",
      "backbone.encoder.layer.6.attention.attention\n",
      "backbone.encoder.layer.6.attention.attention.query\n",
      "backbone.encoder.layer.6.attention.attention.key\n",
      "backbone.encoder.layer.6.attention.attention.value\n",
      "backbone.encoder.layer.6.attention.output\n",
      "backbone.encoder.layer.6.attention.output.dense\n",
      "backbone.encoder.layer.6.attention.output.dropout\n",
      "backbone.encoder.layer.6.layer_scale1\n",
      "backbone.encoder.layer.6.drop_path\n",
      "backbone.encoder.layer.6.norm2\n",
      "backbone.encoder.layer.6.mlp\n",
      "backbone.encoder.layer.6.mlp.fc1\n",
      "backbone.encoder.layer.6.mlp.activation\n",
      "backbone.encoder.layer.6.mlp.fc2\n",
      "backbone.encoder.layer.6.layer_scale2\n",
      "backbone.encoder.layer.7\n",
      "backbone.encoder.layer.7.norm1\n",
      "backbone.encoder.layer.7.attention\n",
      "backbone.encoder.layer.7.attention.attention\n",
      "backbone.encoder.layer.7.attention.attention.query\n",
      "backbone.encoder.layer.7.attention.attention.key\n",
      "backbone.encoder.layer.7.attention.attention.value\n",
      "backbone.encoder.layer.7.attention.output\n",
      "backbone.encoder.layer.7.attention.output.dense\n",
      "backbone.encoder.layer.7.attention.output.dropout\n",
      "backbone.encoder.layer.7.layer_scale1\n",
      "backbone.encoder.layer.7.drop_path\n",
      "backbone.encoder.layer.7.norm2\n",
      "backbone.encoder.layer.7.mlp\n",
      "backbone.encoder.layer.7.mlp.fc1\n",
      "backbone.encoder.layer.7.mlp.activation\n",
      "backbone.encoder.layer.7.mlp.fc2\n",
      "backbone.encoder.layer.7.layer_scale2\n",
      "backbone.encoder.layer.8\n",
      "backbone.encoder.layer.8.norm1\n",
      "backbone.encoder.layer.8.attention\n",
      "backbone.encoder.layer.8.attention.attention\n",
      "backbone.encoder.layer.8.attention.attention.query\n",
      "backbone.encoder.layer.8.attention.attention.key\n",
      "backbone.encoder.layer.8.attention.attention.value\n",
      "backbone.encoder.layer.8.attention.output\n",
      "backbone.encoder.layer.8.attention.output.dense\n",
      "backbone.encoder.layer.8.attention.output.dropout\n",
      "backbone.encoder.layer.8.layer_scale1\n",
      "backbone.encoder.layer.8.drop_path\n",
      "backbone.encoder.layer.8.norm2\n",
      "backbone.encoder.layer.8.mlp\n",
      "backbone.encoder.layer.8.mlp.fc1\n",
      "backbone.encoder.layer.8.mlp.activation\n",
      "backbone.encoder.layer.8.mlp.fc2\n",
      "backbone.encoder.layer.8.layer_scale2\n",
      "backbone.encoder.layer.9\n",
      "backbone.encoder.layer.9.norm1\n",
      "backbone.encoder.layer.9.attention\n",
      "backbone.encoder.layer.9.attention.attention\n",
      "backbone.encoder.layer.9.attention.attention.query\n",
      "backbone.encoder.layer.9.attention.attention.key\n",
      "backbone.encoder.layer.9.attention.attention.value\n",
      "backbone.encoder.layer.9.attention.output\n",
      "backbone.encoder.layer.9.attention.output.dense\n",
      "backbone.encoder.layer.9.attention.output.dropout\n",
      "backbone.encoder.layer.9.layer_scale1\n",
      "backbone.encoder.layer.9.drop_path\n",
      "backbone.encoder.layer.9.norm2\n",
      "backbone.encoder.layer.9.mlp\n",
      "backbone.encoder.layer.9.mlp.fc1\n",
      "backbone.encoder.layer.9.mlp.activation\n",
      "backbone.encoder.layer.9.mlp.fc2\n",
      "backbone.encoder.layer.9.layer_scale2\n",
      "backbone.encoder.layer.10\n",
      "backbone.encoder.layer.10.norm1\n",
      "backbone.encoder.layer.10.attention\n",
      "backbone.encoder.layer.10.attention.attention\n",
      "backbone.encoder.layer.10.attention.attention.query\n",
      "backbone.encoder.layer.10.attention.attention.key\n",
      "backbone.encoder.layer.10.attention.attention.value\n",
      "backbone.encoder.layer.10.attention.output\n",
      "backbone.encoder.layer.10.attention.output.dense\n",
      "backbone.encoder.layer.10.attention.output.dropout\n",
      "backbone.encoder.layer.10.layer_scale1\n",
      "backbone.encoder.layer.10.drop_path\n",
      "backbone.encoder.layer.10.norm2\n",
      "backbone.encoder.layer.10.mlp\n",
      "backbone.encoder.layer.10.mlp.fc1\n",
      "backbone.encoder.layer.10.mlp.activation\n",
      "backbone.encoder.layer.10.mlp.fc2\n",
      "backbone.encoder.layer.10.layer_scale2\n",
      "backbone.encoder.layer.11\n",
      "backbone.encoder.layer.11.norm1\n",
      "backbone.encoder.layer.11.attention\n",
      "backbone.encoder.layer.11.attention.attention\n",
      "backbone.encoder.layer.11.attention.attention.query\n",
      "backbone.encoder.layer.11.attention.attention.key\n",
      "backbone.encoder.layer.11.attention.attention.value\n",
      "backbone.encoder.layer.11.attention.output\n",
      "backbone.encoder.layer.11.attention.output.dense\n",
      "backbone.encoder.layer.11.attention.output.dropout\n",
      "backbone.encoder.layer.11.layer_scale1\n",
      "backbone.encoder.layer.11.drop_path\n",
      "backbone.encoder.layer.11.norm2\n",
      "backbone.encoder.layer.11.mlp\n",
      "backbone.encoder.layer.11.mlp.fc1\n",
      "backbone.encoder.layer.11.mlp.activation\n",
      "backbone.encoder.layer.11.mlp.fc2\n",
      "backbone.encoder.layer.11.layer_scale2\n",
      "backbone.layernorm\n",
      "neck\n",
      "neck.reassemble_stage\n",
      "neck.reassemble_stage.layers\n",
      "neck.reassemble_stage.layers.0\n",
      "neck.reassemble_stage.layers.0.projection\n",
      "neck.reassemble_stage.layers.0.resize\n",
      "neck.reassemble_stage.layers.1\n",
      "neck.reassemble_stage.layers.1.projection\n",
      "neck.reassemble_stage.layers.1.resize\n",
      "neck.reassemble_stage.layers.2\n",
      "neck.reassemble_stage.layers.2.projection\n",
      "neck.reassemble_stage.layers.2.resize\n",
      "neck.reassemble_stage.layers.3\n",
      "neck.reassemble_stage.layers.3.projection\n",
      "neck.reassemble_stage.layers.3.resize\n",
      "neck.convs\n",
      "neck.convs.0\n",
      "neck.convs.1\n",
      "neck.convs.2\n",
      "neck.convs.3\n",
      "neck.fusion_stage\n",
      "neck.fusion_stage.layers\n",
      "neck.fusion_stage.layers.0\n",
      "neck.fusion_stage.layers.0.projection\n",
      "neck.fusion_stage.layers.0.residual_layer1\n",
      "neck.fusion_stage.layers.0.residual_layer1.activation1\n",
      "neck.fusion_stage.layers.0.residual_layer1.convolution1\n",
      "neck.fusion_stage.layers.0.residual_layer1.activation2\n",
      "neck.fusion_stage.layers.0.residual_layer1.convolution2\n",
      "neck.fusion_stage.layers.0.residual_layer2\n",
      "neck.fusion_stage.layers.0.residual_layer2.activation1\n",
      "neck.fusion_stage.layers.0.residual_layer2.convolution1\n",
      "neck.fusion_stage.layers.0.residual_layer2.activation2\n",
      "neck.fusion_stage.layers.0.residual_layer2.convolution2\n",
      "neck.fusion_stage.layers.1\n",
      "neck.fusion_stage.layers.1.projection\n",
      "neck.fusion_stage.layers.1.residual_layer1\n",
      "neck.fusion_stage.layers.1.residual_layer1.activation1\n",
      "neck.fusion_stage.layers.1.residual_layer1.convolution1\n",
      "neck.fusion_stage.layers.1.residual_layer1.activation2\n",
      "neck.fusion_stage.layers.1.residual_layer1.convolution2\n",
      "neck.fusion_stage.layers.1.residual_layer2\n",
      "neck.fusion_stage.layers.1.residual_layer2.activation1\n",
      "neck.fusion_stage.layers.1.residual_layer2.convolution1\n",
      "neck.fusion_stage.layers.1.residual_layer2.activation2\n",
      "neck.fusion_stage.layers.1.residual_layer2.convolution2\n",
      "neck.fusion_stage.layers.2\n",
      "neck.fusion_stage.layers.2.projection\n",
      "neck.fusion_stage.layers.2.residual_layer1\n",
      "neck.fusion_stage.layers.2.residual_layer1.activation1\n",
      "neck.fusion_stage.layers.2.residual_layer1.convolution1\n",
      "neck.fusion_stage.layers.2.residual_layer1.activation2\n",
      "neck.fusion_stage.layers.2.residual_layer1.convolution2\n",
      "neck.fusion_stage.layers.2.residual_layer2\n",
      "neck.fusion_stage.layers.2.residual_layer2.activation1\n",
      "neck.fusion_stage.layers.2.residual_layer2.convolution1\n",
      "neck.fusion_stage.layers.2.residual_layer2.activation2\n",
      "neck.fusion_stage.layers.2.residual_layer2.convolution2\n",
      "neck.fusion_stage.layers.3\n",
      "neck.fusion_stage.layers.3.projection\n",
      "neck.fusion_stage.layers.3.residual_layer1\n",
      "neck.fusion_stage.layers.3.residual_layer1.activation1\n",
      "neck.fusion_stage.layers.3.residual_layer1.convolution1\n",
      "neck.fusion_stage.layers.3.residual_layer1.activation2\n",
      "neck.fusion_stage.layers.3.residual_layer1.convolution2\n",
      "neck.fusion_stage.layers.3.residual_layer2\n",
      "neck.fusion_stage.layers.3.residual_layer2.activation1\n",
      "neck.fusion_stage.layers.3.residual_layer2.convolution1\n",
      "neck.fusion_stage.layers.3.residual_layer2.activation2\n",
      "neck.fusion_stage.layers.3.residual_layer2.convolution2\n",
      "head\n",
      "head.conv1\n",
      "head.conv2\n",
      "head.activation1\n",
      "head.conv3\n",
      "head.activation2\n"
     ]
    }
   ],
   "source": [
    "# Afficher les noms de toutes les couches (modules) du modèle\n",
    "print(\"Noms de toutes les couches du modèle :\")\n",
    "for name, module in model.named_modules():\n",
    "    if name:  # Éviter la racine vide\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cf6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration LoRA Correcte pour la Vision\n",
    "# On cible tous les modules linéaires du Transformer pour un meilleur apprentissage\n",
    "# On retire 'task_type' pour éviter l'erreur \"input_ids\"\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=128,\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\", \"fc1\", \"fc2\"], \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77586d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,327,104 || all params: 26,112,193 || trainable%: 5.0823\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17db4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Trainer Personnalisé pour gérer la Loss et les NaNs\n",
    "class DepthTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "        \n",
    "        # L'output du modèle peut être légèrement différent de la taille d'entrée (padding)\n",
    "        # On s'assure que la prédiction matche les labels\n",
    "        if predicted_depth.shape[-2:] != labels.shape[-2:]:\n",
    "            predicted_depth = F.interpolate(\n",
    "                predicted_depth.unsqueeze(1), \n",
    "                size=labels.shape[-2:], \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            ).squeeze(1)\n",
    "\n",
    "        # Masquage des valeurs invalides (NaNs ou inf)\n",
    "        # On suppose que la profondeur valide est > 0 et n'est pas NaN\n",
    "        valid_mask = ~torch.isnan(labels) & ~torch.isinf(labels) & (labels > 0)\n",
    "        \n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predicted_depth.device, requires_grad=True)\n",
    "\n",
    "        # Calcul de la Loss (L1 Loss est souvent mieux pour la profondeur que MSE)\n",
    "        loss = F.l1_loss(predicted_depth[valid_mask], labels[valid_mask])\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d10e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"output_depth_lora\",\n",
    "    learning_rate=2e-4,              # Augmenté légèrement\n",
    "    lr_scheduler_type=\"cosine\",      # Ajout du scheduler\n",
    "    warmup_ratio=0.1,                # Ajout du warmup\n",
    "    weight_decay=0.01,               # Ajout de la régularisation\n",
    "    per_device_train_batch_size=4,   # OK pour 2080 Ti (11GB VRAM)\n",
    "    gradient_accumulation_steps=4,   # Taille de batch effective = 4*4*NB_GPU\n",
    "    num_train_epochs=30,             # 50 est peut-être long, surveillez l'eval_loss\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,     # Important\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc639693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de collation simple\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    return {'pixel_values': pixel_values, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8499ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 07:36, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>305.727722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>301.106995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>296.783386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>330.259000</td>\n",
       "      <td>292.379883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>330.259000</td>\n",
       "      <td>289.932190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>330.259000</td>\n",
       "      <td>288.336639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>317.107200</td>\n",
       "      <td>287.317108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>317.107200</td>\n",
       "      <td>286.284180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>317.107200</td>\n",
       "      <td>285.376862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>312.358200</td>\n",
       "      <td>284.539398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>312.358200</td>\n",
       "      <td>283.782471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>312.358200</td>\n",
       "      <td>283.079346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>312.358200</td>\n",
       "      <td>282.440125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>311.730900</td>\n",
       "      <td>281.878143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>311.730900</td>\n",
       "      <td>281.377808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>311.730900</td>\n",
       "      <td>280.959686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>308.068000</td>\n",
       "      <td>280.616089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>308.068000</td>\n",
       "      <td>280.327057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>308.068000</td>\n",
       "      <td>280.106079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>307.075700</td>\n",
       "      <td>279.964630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>307.075700</td>\n",
       "      <td>279.790405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>307.075700</td>\n",
       "      <td>279.671295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>307.075700</td>\n",
       "      <td>279.572113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>309.225900</td>\n",
       "      <td>279.474731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>309.225900</td>\n",
       "      <td>279.391479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>309.225900</td>\n",
       "      <td>279.328796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>307.599100</td>\n",
       "      <td>279.271912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>307.599100</td>\n",
       "      <td>279.227020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>307.599100</td>\n",
       "      <td>279.176605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>307.420900</td>\n",
       "      <td>279.132751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>307.420900</td>\n",
       "      <td>279.096710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>307.420900</td>\n",
       "      <td>279.065491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>307.420900</td>\n",
       "      <td>279.039093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>305.837500</td>\n",
       "      <td>279.016876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>305.837500</td>\n",
       "      <td>278.994354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>305.837500</td>\n",
       "      <td>278.976715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>307.361800</td>\n",
       "      <td>278.965424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>307.361800</td>\n",
       "      <td>278.949585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>307.361800</td>\n",
       "      <td>278.933807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>308.446500</td>\n",
       "      <td>278.924438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>308.446500</td>\n",
       "      <td>278.911163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>308.446500</td>\n",
       "      <td>278.901276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>308.446500</td>\n",
       "      <td>278.892273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>305.358000</td>\n",
       "      <td>278.883209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>305.358000</td>\n",
       "      <td>278.874481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>305.358000</td>\n",
       "      <td>278.868347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>307.207700</td>\n",
       "      <td>278.861450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>307.207700</td>\n",
       "      <td>278.857910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>307.207700</td>\n",
       "      <td>278.854156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>308.325000</td>\n",
       "      <td>278.853333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=310.225419921875, metrics={'train_runtime': 460.0897, 'train_samples_per_second': 4.347, 'train_steps_per_second': 0.326, 'total_flos': 4.0902974705376e+17, 'train_loss': 310.225419921875, 'epoch': 50.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Lancement\n",
    "trainer = DepthTrainer(\n",
    "    model=lora_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872ebe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e2e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c1c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
